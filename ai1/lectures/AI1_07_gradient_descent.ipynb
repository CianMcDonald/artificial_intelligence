{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Gradient Descent</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Acknowledgement</h1>\n",
    "<ul>\n",
    "    <li>I based 5 of the diagrams on ones to be found in A. G&eacute;ron: <i>Hands-On Machine Learning with Scikit-Learn, Keras &amp;\n",
    "        TensorFlow (2nd edn)</i>, O'Reilly, 2019\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li><b>Gradient Descent</b> is a generic method for finding optimal solutions to problems that involve\n",
    "        minimizing a loss function.\n",
    "    </li>\n",
    "    <li>It is a <em>search</em> in the model's <b>parameter space</b> for values of the parameters that minimize \n",
    "        the loss function.\n",
    "    </li>\n",
    "    <li>Conceptually:\n",
    "        <ul>\n",
    "            <li>\n",
    "                 It starts with an initial guess for the values of the parameters.\n",
    "            </li>\n",
    "            <li>\n",
    "                Then repeatedly:\n",
    "                <ul>\n",
    "                    <li>It updates the parameter values  &mdash; hopefully to reduce the loss.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <!-- <img src=\"images/fog.jpg\" alt=\"\" /> -->\n",
    "    </li>\n",
    "    <li>\n",
    "        Ideally, it keeps doing this until <b>convergence</b> &mdash; changes to the parameter values do not result\n",
    "        in lower loss.\n",
    "    </li>\n",
    "    <li>The key to this algorithm is how to update the parameter values.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>The update rule</h2>\n",
    "<ul>\n",
    "     <li>To update the parameter values to reduce the loss:\n",
    "         <ul>\n",
    "             <li>Compute the gradient vector.\n",
    "                 <ul>\n",
    "                     <li>But this points 'uphill' and we want to go 'downhill'.</li>\n",
    "                     <li>And we want to make 'baby steps' (see later), so we use a <b>learning rate</b>, \n",
    "                         $\\alpha$, which is between 0 and 1.\n",
    "                     </li>\n",
    "                 </ul>\n",
    "             </li>\n",
    "             <li>So subtract $\\alpha$ times the gradient vector from $\\v{\\beta}$.</li>\n",
    "         </ul>\n",
    "         $$\\v{\\beta} \\gets \\v{\\beta} - \\alpha\\nabla_{\\v{\\beta}}J(\\v{X}, \\v{y}, \\v{\\beta})$$\n",
    "         Or\n",
    "         $$\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$$\n",
    "     </li>\n",
    "     <li>(BTW, this is vectorized. Naive loop implementations are wrong: they lose the\n",
    "         <em>simultaneous</em> update of the $\\v{\\beta}_j$.)\n",
    "     </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Gradient descent algorithm</h2>\n",
    "<ul>\n",
    "    <li>Pseudocode (in fact, this is for <b>batch gradient descent</b>, see later):\n",
    "        <ul style=\"background: lightgrey; list-style: none\">\n",
    "            <li>initialize $\\v{\\beta}$ randomly\n",
    "            <li>\n",
    "                repeat until convergence\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        $\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$\n",
    "                    </li>\n",
    "                </ul>\n",
    "             </li>\n",
    "        </ul>\n",
    "    </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Baby steps</h2>\n",
    "<ul>\n",
    "    <li>We'll use  an example with a single feature/single parameter $\\beta_1$ in order to visualize.</li>\n",
    "    <li>We update $\\beta_1$ gradually, one baby step at a time, unitl the algorithm converges on minimum loss:\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps1.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>The size of the steps is determined by <!--a <b>hyperparameter</b> called--> the learning rate.\n",
    "    <!--\n",
    "        <ul>\n",
    "            <li>(Hyperparamters are explained in CS4619)</li>\n",
    "        </ul>\n",
    "       -->\n",
    "    </li>\n",
    "    <li>If the learning rate is too small, it will take many updates until convergence:\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps2.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>If the learning rate is too big, the algorithm might jump across the valley &mdash; it may even end up with\n",
    "        higher loss than before, making the next step bigger.\n",
    "        <ul>\n",
    "            <li>This might make the algorithm <b>diverge</b>.\n",
    "            </li>\n",
    "        </ul>\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps3.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Why we need to scale for Gradient Descent</h2>\n",
    "<ul>\n",
    "    <li>If we are doing OLS regression using the Normal Equation, we do not need to scale the features.\n",
    "        But if we are doing OLS regression using Gradient Descent, we do need to scale the features.\n",
    "    </li>\n",
    "    <li>If features have different ranges, it affects the shape of the 'bowl'.</li>\n",
    "    <li>E.g. features 1 and 2 have similar ranges of values &mdash; a 'bowl':\n",
    "        <figure>\n",
    "            <img src=\"images/scaled.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>The algorithm goes straight towards the minimum.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>E.g. feature 1 has smaller values than feature 2 &mdash; an elongated 'bowl':\n",
    "        <figure>\n",
    "            <img src=\"images/unscaled.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>Since feature 1 has smaller values, it takes a larger change in $\\v{\\beta}_1$ to affect \n",
    "                the loss function, which is why it is elongated.\n",
    "            </li>\n",
    "            <li>It takes more steps to get to the minimum &mdash; steeply down but not really towards the\n",
    "                goal, followed by a long march down a nearly flat valley.\n",
    "            </li>\n",
    "            <li>It makes it more difficult to choose a value for the learning rate that avoids divergence:\n",
    "                a value that suits one feature may not suit another.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Variants of Gradient Descent</h2>\n",
    "<ul>\n",
    "    <li>There are, in fact, three variants:\n",
    "        <ul>\n",
    "            <li>Batch Gradient Descent;</li>\n",
    "            <li>Stochastic Gradient Descent; and</li>\n",
    "            <li>Mini-batch Gradient Descent.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Batch Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>The pseudocode we saw earlier (repeated here for convenience) is Batch Gradient Descent:\n",
    "        <ul style=\"background: lightgrey; list-style: none\">\n",
    "            <li>initialize $\\v{\\beta}$ randomly\n",
    "            <li>\n",
    "                repeat until convergence\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        $\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$\n",
    "                    </li>\n",
    "                </ul>\n",
    "             </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Why is it called <em>Batch</em> Gradient Descent?\n",
    "        <ul>\n",
    "            <li>The update involves a calculation over the <em>entire</em> training set $\\v{X}$\n",
    "                on every iteration.\n",
    "            </li>\n",
    "            <li>This can be slow for large training sets.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Batch Gradient Descent in numpy</h2>\n",
    "<ul>\n",
    "    <li>For the hell of it, let's implement it ourselves.</li>\n",
    "    <li>Again for the purposes of this explanation, we will use the entire dataset as our training set.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for OLS regression (assumes X contains all 1s in its first column)\n",
    "def J(X, y, beta):\n",
    "    return np.mean((X.dot(beta) - y) ** 2) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent_for_ols_linear_regression(X, y, alpha, num_iterations):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_iterations)\n",
    "    \n",
    "    for iter in range(num_iterations):\n",
    "        beta -= (1.0 * alpha / m) * X.T.dot(X.dot(beta) - y)\n",
    "        Jvals[iter] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Add the extra column to X\n",
    "X = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.52297328e+02, 1.75213552e+02, 3.49912320e-01, 1.46027196e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Batch Gradient Descent\n",
    "beta, Jvals = batch_gradient_descent_for_ols_linear_regression(X, y, alpha = 0.03, num_iterations = 500)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Bear in mind that the coefficients it finds are on the scaled data.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>It's a good idea to plot the values of the loss function against the number of iterations.\n",
    "    </li>\n",
    "    <li>For OLS regression done using Batch Gradient Descent, if the loss ever increases, then:\n",
    "        <ul>\n",
    "            <li>\n",
    "                the code might be incorrect; or\n",
    "            </li>\n",
    "            <li>\n",
    "                the value of $\\alpha$ is too big and is causing divergence.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>The algorithm gives us the problem of choosing the number of iterations.</li>\n",
    "    <li>An alternative is to use a very large number of iterations but exit when the gradient vector\n",
    "        becomes tiny:\n",
    "        <ul>\n",
    "            <li>when its norm becomes smaller than <b>tolerance</b>, $\\eta$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Here's an interactive version that allows you to choose the value of $\\alpha$ and to decide\n",
    "        whether to scale the data or not.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163bd113193b47afbb48463b59bb2acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='scale'), Dropdown(description='alpha', options=(('0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bgd(scale=True, alpha=0.03):\n",
    "    # Get the feature-values and the target values \n",
    "    X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "    y = df[\"price\"].values\n",
    "    # Scale the data, if requested\n",
    "    if scale:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    # Add the extra column to X\n",
    "    X = add_dummy_feature(X)\n",
    "    # Run the Batch Gradient Descent\n",
    "    beta, Jvals = batch_gradient_descent_for_ols_linear_regression(X, y, alpha, num_iterations = 3000)\n",
    "    # Display beta\n",
    "    print(\"beta: \", beta)\n",
    "    # Plot loss\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.title(\"$J$ during learning\")\n",
    "    plt.xlabel(\"Number of iterations\")\n",
    "    plt.xlim(1, Jvals.size)\n",
    "    plt.ylabel(\"$J$\")\n",
    "    plt.ylim(3500, 50000)\n",
    "    xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "    plt.scatter(xvals, Jvals)\n",
    "    plt.show()\n",
    "    \n",
    "interactive_plot = interactive(bgd, {'manual': True}, \n",
    "    scale=True, alpha=[(\"0.00009\", 0.00009), (\"0.0009\", 0.0009), (\"0.009\", 0.009), (\"0.09\", 0.09), (\"0.9\", 0.9)]) \n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>\n",
    "        Some people suggest a variant of Batch Gradient Descent in which the value of $\\alpha$ is decreased\n",
    "        over time, i.e. its value in later iterations is smaller\n",
    "        <ul>\n",
    "            <li>Why do they suggest this? </li>\n",
    "            <li>And why isn't it necessary?\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>(But, we'll revisit this idea in Stochastic Gradient Descent.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Stochastic Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>As we saw, in each iteration, Batch Gradient Descent does a calculation on the entire\n",
    "        training set, which, for large training sets, may be slow.\n",
    "    </li>\n",
    "    <li><b>Stochastic Gradient Descent (SGD)</b>:\n",
    "        <ul>\n",
    "            <li>On each iteration, it picks just <em>one</em> training example $\\v{x}$ at random and computes \n",
    "                the gradients on just that\n",
    "                one example\n",
    "                $$\\v{\\beta} \\gets \\v{\\beta} - \\alpha\\v{x}^T(\\v{x}\\v{\\beta} - y)$$\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>This gives huge speed-up.</li>\n",
    "    <li>It enables us to train on huge training sets since only one example needs to be in memory in each iteration.\n",
    "    </li>\n",
    "    <li>But, because it is stochastic (the randomness), the loss will not necessarily decrease on each iteration:\n",
    "        <ul>\n",
    "            <li><em>On average</em>, the loss decreases, but in any one iteration, loss may go up or down.</li>\n",
    "            <li>Eventually, it will get close to the minimum, but it will continue to go up and down a bit.\n",
    "                <ul>\n",
    "                    <li>So, once you stop it, the $\\v{\\beta}$ will be close to the best, but not \n",
    "                        necessarily optimal.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>SGD in scikit-learn</h2>\n",
    "<ul>\n",
    "    <li>The <code>fit</code> method of scikit-learn's <code>SGDRegressor</code> class is doing\n",
    "        what we have described:\n",
    "        <ul>\n",
    "            <li>You must scale the features but it inserts the extra column of 1s for us.</li>\n",
    "            <li>You can supply a <code>learning_rate</code> and lots of other things\n",
    "                (in the code below, we'll just use the defaults).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>(Again, we'll train on the whole dataset.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Create the SGDRegressor and fit the model\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>SGD in numpy</h2>\n",
    "<ul>\n",
    "    <li>For the hell of it, let's implement a simple version ourselves</li>\n",
    "    <li>(Again, we'll train on the whole dataset.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_for_ols_linear_regression(X, y, alpha, num_epochs):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_epochs * m)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(m):\n",
    "            rand_idx = np.random.randint(m)\n",
    "            xi = X[rand_idx:rand_idx + 1]\n",
    "            yi = y[rand_idx:rand_idx + 1]\n",
    "            beta -= alpha * xi.T.dot(xi.dot(beta) - yi)\n",
    "            Jvals[epoch * m + i] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>(One common alternative to the code above is to shuffle between epochs and remove the randomness within the\n",
    "        inner loop.)\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Add the extra column to X\n",
    "X = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([358.06375681, 197.04266553,  28.68366746,  24.02228386])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Stochastic Gradient Descent\n",
    "beta, Jvals = stochastic_gradient_descent_for_ols_linear_regression(X, y, alpha = 0.03, num_epochs = 50)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Quite a bumpy ride!</li>\n",
    "    <li>So, let's try <b>simulated annealing</b>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Simulated Annealing</h2>\n",
    "<ul>\n",
    "    <li>As we discussed, SGD does not settle at the minimum.</li>\n",
    "    <li>One solution is to gradually reduce the learning rate:\n",
    "        <ul>\n",
    "            <li>Updates start out 'large' so you make progress.</li>\n",
    "            <li>But, over time, updates get smaller, allowing SGD to settle at or near the global minimum.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The function that determines how to reduce the learning rate is called the <b>learning schedule</b>.\n",
    "        <ul>\n",
    "            <li>Reduce it too quickly and you may not converge on or near to the global minimum.</li>\n",
    "            <li>Reduce it too slowly and you may still bounce around a lot and, if stopped after too few iterations, \n",
    "                may end up\n",
    "                with a suboptimal solution.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)\n",
    "    \n",
    "def stochastic_gradient_descent_for_ols_linear_regression_with_simulated_annealing(X, y, num_epochs):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_epochs * m)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(m):\n",
    "            rand_idx = np.random.randint(m)\n",
    "            xi = X[rand_idx:rand_idx + 1]\n",
    "            yi = y[rand_idx:rand_idx + 1]\n",
    "            alpha = learning_schedule(epoch * m + i)\n",
    "            beta -= alpha * xi.T.dot(xi.dot(beta) - yi)\n",
    "            Jvals[epoch * m + i] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([353.84274394, 177.76475563,   0.70022983,   1.36663519])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Stochastic Gradient Descent\n",
    "beta, Jvals = stochastic_gradient_descent_for_ols_linear_regression_with_simulated_annealing(X, y, num_epochs = 50)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Mini-Batch Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>Batch Gradient Descent computes gradients from the full training set.</li>\n",
    "    <li>Stochastic Gradient Descent computes gradients from just one example.</li>\n",
    "    <li>Mini-Batch Gradient Descent lies between the two:\n",
    "        <ul>\n",
    "            <li>It computes gradients from a small randomly-selected subset of the training set, called a\n",
    "                <b>mini-batch</b>.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Since it lies between the two:\n",
    "        <ul>\n",
    "            <li>It may bounce less and get closer to the global minimum than SGD&hellip;\n",
    "                <ul>\n",
    "                    <li>&hellip;although both of them can reach the global minimum with a good learning schedule.</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Its time and memory costs lie between the two.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The Normal Equation versus Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>Efficiency/scaling-up to large training sets:\n",
    "        <ul>\n",
    "            <li>Normal Equation: \n",
    "                <ul>\n",
    "                    <li>is linear in $m$, so can handle large training sets efficiently if they fit into\n",
    "                        main memory;\n",
    "                    </li>\n",
    "                    <li>but it has to compute the inverse (or psueudo-inverse) of a $n \\times n$ matrix, which takes\n",
    "                        time between quadratic and cubic in $n$, and so is only feasible for smallish $n$ (up to\n",
    "                        a few thousand).\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Gradient Descent:\n",
    "                <ul>\n",
    "                    <li>SGD scales really well to huge $m$;</li>\n",
    "                    <li>All three Gradient Descent methods can handle huge $n$ (even 100s of 1000s).</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Finding the global minimum for OLS regression:\n",
    "        <ul>\n",
    "            <li>Normal Equation: guaranteed to find the global minimum.</li>\n",
    "            <li>Gradient Descent: all a bit dependent on number of iterations, learning rate, learning schedule.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Feature scaling:\n",
    "        <ul>\n",
    "            <li>Normal Equation: scaling is not needed. \n",
    "            </li>\n",
    "            <li>Gradient Descent: scaling <em>is</em> needed.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Finally, Gradient Descent is a general method, whereas the Normal Equation is only for OLS regression.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Non-Convex Functions</h1>\n",
    "<ul>\n",
    "    <li>The loss function for OLS regression is convex and it has a slope that never changes abruptly.\n",
    "        <ul>\n",
    "            <li>This gives us good 'guarantees' about reaching the minimum\n",
    "                (depending on such things as running for long enough, using a learning rate that isn't too high,\n",
    "                and whether we are using Batch, Mini-Batch or Stochastic Gradient Descent).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>But Gradient Descent is a generic method: you can use it to find the minima of other loss functions.</li>\n",
    "    <li>Not all loss functions are convex, which can cause problems for Gradient Descent:\n",
    "        <figure>\n",
    "            <img src=\"images/local_minima.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>The algorithm might converge to a local minimum, instead of the global minimum.</li>\n",
    "            <li>It may take a long time to cross a plateau.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>What do we do about this?\n",
    "        <ul>\n",
    "            <li>One thing is to prefer Stochastic Gradient Descent (or Mini-Batch Gradient Descent):\n",
    "                because of the way they 'bounce around', they might even escape a\n",
    "                local minimum, and might even get to the global minimum.\n",
    "            </li>\n",
    "            <li>In this context, simulated annealing is also useful: updates start out 'large' allowing these\n",
    "                algorithms to make \n",
    "                progress and even escape local minima; but, over time, updates get smaller, allowing \n",
    "                these algorithms to settle at or near the global minimum.\n",
    "            </li>\n",
    "            <li>But, if using simulated annealing, if you reduce the learning rate too quickly, you may \n",
    "                stil get stuck in a local minimum.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
