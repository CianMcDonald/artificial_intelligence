{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Gradient Descent</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interactive\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Acknowledgement</h1>\n",
    "<ul>\n",
    "    <li>I based 5 of the diagrams on ones to be found in A. G&eacute;ron: <i>Hands-On Machine Learning with Scikit-Learn, Keras &amp;\n",
    "        TensorFlow (2nd edn)</i>, O'Reilly, 2019\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li><b>Gradient Descent</b> is a generic method for finding optimal solutions to problems that involve\n",
    "        minimizing a loss function.\n",
    "    </li>\n",
    "    <li>It is a <em>search</em> in the model's <b>parameter space</b> for values of the parameters that minimize \n",
    "        the loss function.\n",
    "    </li>\n",
    "    <li>Conceptually:\n",
    "        <ul>\n",
    "            <li>\n",
    "                 It starts with an initial guess for the values of the parameters.\n",
    "            </li>\n",
    "            <li>\n",
    "                Then repeatedly:\n",
    "                <ul>\n",
    "                    <li>It updates the parameter values  &mdash; hopefully to reduce the loss.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <img src=\"images/fog.jpg\" alt=\"\" />\n",
    "    </li>\n",
    "    <li>\n",
    "        Ideally, it keeps doing this until <b>convergence</b> &mdash; changes to the parameter values do not result\n",
    "        in lower loss.\n",
    "    </li>\n",
    "    <li>The key to this algorithm is how to update the parameter values.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>The update rule</h2>\n",
    "<ul>\n",
    "     <li>To update the parameter values to reduce the loss:\n",
    "         <ul>\n",
    "             <li>Compute the gradient vector.\n",
    "                 <ul>\n",
    "                     <li>But this points 'uphill' and we want to go 'downhill'.</li>\n",
    "                     <li>And we want to make 'baby steps' (see later), so we use a <b>learning rate</b>, \n",
    "                         $\\alpha$, which is between 0 and 1.\n",
    "                     </li>\n",
    "                 </ul>\n",
    "             </li>\n",
    "             <li>So subtract $\\alpha$ times the gradient vector from $\\v{\\beta}$.</li>\n",
    "         </ul>\n",
    "         $$\\v{\\beta} \\gets \\v{\\beta} - \\alpha\\nabla_{\\v{\\beta}}J(\\v{X}, \\v{y}, \\v{\\beta})$$\n",
    "         Or\n",
    "         $$\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$$\n",
    "     </li>\n",
    "     <li>(BTW, this is vectorized. Naive loop implementations are wrong: they lose the\n",
    "         <em>simultaneous</em> update of the $\\v{\\beta}_j$.)\n",
    "     </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Gradient descent algorithm</h2>\n",
    "<ul>\n",
    "    <li>Pseudocode (in fact, this is for <b>batch gradient descent</b>, see later):\n",
    "        <ul style=\"background: lightgrey; list-style: none\">\n",
    "            <li>initialize $\\v{\\beta}$ randomly\n",
    "            <li>\n",
    "                repeat until convergence\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        $\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$\n",
    "                    </li>\n",
    "                </ul>\n",
    "             </li>\n",
    "        </ul>\n",
    "    </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Baby steps</h2>\n",
    "<ul>\n",
    "    <li>We'll use  an example with a single feature/single parameter $\\beta_1$ in order to visualize.</li>\n",
    "    <li>We update $\\beta_1$ gradually, one baby step at a time, unitl the algorithm converges on minimum loss:\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps1.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>The size of the steps is determined by <!--a <b>hyperparameter</b> called--> the learning rate.\n",
    "    <!--\n",
    "        <ul>\n",
    "            <li>(Hyperparamters are explained in CS4619)</li>\n",
    "        </ul>\n",
    "       -->\n",
    "    </li>\n",
    "    <li>If the learning rate is too small, it will take many updates until convergence:\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps2.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "    <li>If the learning rate is too big, the algorithm might jump across the valley &mdash; it may even end up with\n",
    "        higher loss than before, making the next step bigger.\n",
    "        <ul>\n",
    "            <li>This might make the algorithm <b>diverge</b>.\n",
    "            </li>\n",
    "        </ul>\n",
    "        <figure>\n",
    "            <img src=\"images/baby_steps3.png\" />\n",
    "        </figure>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Why we need to scale for Gradient Descent</h2>\n",
    "<ul>\n",
    "    <li>If we are doing OLS regression using the Normal Equation, we do not need to scale the features.\n",
    "        But if we are doing OLS regression using Gradient Descent, we do need to scale the features.\n",
    "    </li>\n",
    "    <li>If features have different ranges, it affects the shape of the 'bowl'.</li>\n",
    "    <li>E.g. features 1 and 2 have similar ranges of values &mdash; a 'bowl':\n",
    "        <figure>\n",
    "            <img src=\"images/scaled.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>The algorithm goes straight towards the minimum.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>E.g. feature 1 has smaller values than feature 2 &mdash; an elongated 'bowl':\n",
    "        <figure>\n",
    "            <img src=\"images/unscaled.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>Since feature 1 has smaller values, it takes a larger change in $\\v{\\beta}_1$ to affect \n",
    "                the loss function, which is why it is elongated.\n",
    "            </li>\n",
    "            <li>It takes more steps to get to the minimum &mdash; steeply down but not really towards the\n",
    "                goal, followed by a long march down a nearly flat valley.\n",
    "            </li>\n",
    "            <li>It makes it more difficult to choose a value for the learning rate that avoids diveregence:\n",
    "                a value that suits one feature may not suit another.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Variants of Gradient Descent</h2>\n",
    "<ul>\n",
    "    <li>There are, in fact, three variants:\n",
    "        <ul>\n",
    "            <li>Batch Gradient Descent;</li>\n",
    "            <li>Stochastic Gradient Descent; and</li>\n",
    "            <li>Mini-batch Gradient Descent.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Batch Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>The pseudocode we saw earlier (repeated here for convenience) is Batch Gradient Descent:\n",
    "        <ul style=\"background: lightgrey; list-style: none\">\n",
    "            <li>initialize $\\v{\\beta}$ randomly\n",
    "            <li>\n",
    "                repeat until convergence\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        $\\v{\\beta} \\gets \\v{\\beta} - \\frac{\\alpha}{m}\\v{X}^T(\\v{X}\\v{\\beta} - \\v{y})$\n",
    "                    </li>\n",
    "                </ul>\n",
    "             </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Why is it called <em>Batch</em> Gradient Descent?\n",
    "        <ul>\n",
    "            <li>The update involves a calculation over the <em>entire</em> training set $\\v{X}$\n",
    "                on every iteration.\n",
    "            </li>\n",
    "            <li>This can be slow for large training sets.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Batch Gradient Descent in numpy</h2>\n",
    "<ul>\n",
    "    <li>For the hell of it, let's implement it ourselves.</li>\n",
    "    <li>Again for the purposes of this explanation, we will use the entire dataset as our training set.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for OLS regression (assumes X contains all 1s in its first column)\n",
    "def J(X, y, beta):\n",
    "    return np.mean((X.dot(beta) - y) ** 2) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent_for_ols_linear_regression(X, y, alpha, num_iterations):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_iterations)\n",
    "    \n",
    "    for iter in range(num_iterations):\n",
    "        beta -= (1.0 * alpha / m) * X.T.dot(X.dot(beta) - y)\n",
    "        Jvals[iter] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Add the extra column to X\n",
    "X = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([352.29732832, 175.18598318,   0.36631538,   1.47271117])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Batch Gradient Descent\n",
    "beta, Jvals = batch_gradient_descent_for_ols_linear_regression(X, y, alpha = 0.03, num_iterations = 500)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Bear in mind that the coefficients it finds are on the scaled data.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>It's a good idea to plot the values of the loss function against the number of iterations.\n",
    "    </li>\n",
    "    <li>For OLS regression done using Batch Gradient Descent, if the loss ever increases, then:\n",
    "        <ul>\n",
    "            <li>\n",
    "                the code might be incorrect; or\n",
    "            </li>\n",
    "            <li>\n",
    "                the value of $\\alpha$ is too big and is causing divergence.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>The algorithm gives us the problem of choosing the number of iterations.</li>\n",
    "    <li>An alternative is to use a very large number of iterations but exit when the gradient vector\n",
    "        becomes tiny:\n",
    "        <ul>\n",
    "            <li>when its norm becomes smaller than <b>tolerance</b>, $\\eta$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Here's an interactive version that allows you to choose the value of $\\alpha$ and to decide\n",
    "        whether to scale the data or not.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7339ce81364bc9903b95d1e0892769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=True, description='scale'), Dropdown(description='alpha', options=(('0.00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bgd(scale=True, alpha=0.03):\n",
    "    # Get the feature-values and the target values \n",
    "    X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "    y = df[\"price\"].values\n",
    "    # Scale the data, if requested\n",
    "    if scale:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "    # Add the extra column to X\n",
    "    X = add_dummy_feature(X)\n",
    "    # Run the Batch Gradient Descent\n",
    "    beta, Jvals = batch_gradient_descent_for_ols_linear_regression(X, y, alpha, num_iterations = 3000)\n",
    "    # Display beta\n",
    "    print(\"beta: \", beta)\n",
    "    # Plot loss\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.title(\"$J$ during learning\")\n",
    "    plt.xlabel(\"Number of iterations\")\n",
    "    plt.xlim(1, Jvals.size)\n",
    "    plt.ylabel(\"$J$\")\n",
    "    plt.ylim(3500, 50000)\n",
    "    xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "    plt.scatter(xvals, Jvals)\n",
    "    plt.show()\n",
    "    \n",
    "interactive_plot = interactive(bgd, {'manual': True}, \n",
    "    scale=True, alpha=[(\"0.00009\", 0.00009), (\"0.0009\", 0.0009), (\"0.009\", 0.009), (\"0.09\", 0.09), (\"0.9\", 0.9)]) \n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>\n",
    "        Some people suggest a variant of Batch Gradient Descent in which the value of $\\alpha$ is decreased\n",
    "        over time, i.e. its value in later iterations is smaller\n",
    "        <ul>\n",
    "            <li>Why do they suggest this? </li>\n",
    "            <li>And why isn't it necessary?\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>(But, we'll revisit this idea in Stochastic Gradient Descent.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Stochastic Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>As we saw, in each iteration, Batch Gradient Descent does a calculation on the entire\n",
    "        training set, which, for large training sets, may be slow.\n",
    "    </li>\n",
    "    <li><b>Stochastic Gradient Descent (SGD)</b>:\n",
    "        <ul>\n",
    "            <li>On each iteration, it picks just <em>one</em> training example $\\v{x}$ at random and computes \n",
    "                the gradients on just that\n",
    "                one example\n",
    "                $$\\v{\\beta} \\gets \\v{\\beta} - \\alpha\\v{x}^T(\\v{x}\\v{\\beta} - \\v{y})$$\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>This gives huge speed-up.</li>\n",
    "    <li>It enables us to train on huge training sets since only one example needs to be in memory in each iteration.\n",
    "    </li>\n",
    "    <li>But, because it is stochastic (the randomness), the loss will not necessarily decrease on each iteration:\n",
    "        <ul>\n",
    "            <li><em>On average</em>, the loss decreases, but in any one iteration, loss may go up or down.</li>\n",
    "            <li>Eventually, it will get close to the minimum, but it will continue to go up and down a bit.\n",
    "                <ul>\n",
    "                    <li>So, once you stop it, the $\\v{\\beta}$ will be close to the best, but not \n",
    "                        necessarily optimal.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>SGD in scikit-learn</h2>\n",
    "<ul>\n",
    "    <li>The <code>fit</code> method of scikit-learn's <code>SGDRegressor</code> class is doing\n",
    "        what we have described:\n",
    "        <ul>\n",
    "            <li>You must scale the features but it inserts the extra column of 1s for us.</li>\n",
    "            <li>You can supply a <code>learning_rate</code> and lots of other things\n",
    "                (in the code below, we'll just use the defaults).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>(Again, we'll train on the whole dataset.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Create the SGDRegressor and fit the model\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>SGD in numpy</h2>\n",
    "<ul>\n",
    "    <li>For the hell of it, let's implement a simple version ourselves</li>\n",
    "    <li>(Again, we'll train on the whole dataset.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent_for_ols_linear_regression(X, y, alpha, num_epochs):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_epochs * m)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(m):\n",
    "            rand_idx = np.random.randint(m)\n",
    "            xi = X[rand_idx:rand_idx + 1]\n",
    "            yi = y[rand_idx:rand_idx + 1]\n",
    "            beta -= alpha * xi.T.dot(xi.dot(beta) - yi)\n",
    "            Jvals[epoch * m + i] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>(One common alternative to the code above is to shuffle between epochs and remove the randomness within the\n",
    "        inner loop.)\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature-values and the target values \n",
    "X = df[[\"flarea\", \"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Scale it\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Add the extra column to X\n",
    "X = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([344.02655246, 187.82981714, -12.5300742 ,  -7.30668866])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Stochastic Gradient Descent\n",
    "beta, Jvals = stochastic_gradient_descent_for_ols_linear_regression(X, y, alpha = 0.03, num_epochs = 50)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Quite a bumpy ride!</li>\n",
    "    <li>So, let's try <b>simulated annealing</b>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Simulated Annealing</h2>\n",
    "<ul>\n",
    "    <li>As we discussed, SGD does not settle at the minimum.</li>\n",
    "    <li>One solution is to gradually reduce the learning rate:\n",
    "        <ul>\n",
    "            <li>Updates start out 'large' so you make progress.</li>\n",
    "            <li>But, over time, updates get smaller, allowing SGD to settle at or near the global minimum.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The function that determines how to reduce the learning rate is called the <b>learning schedule</b>.\n",
    "        <ul>\n",
    "            <li>Reduce it too quickly and you may not converge on or near to the global minimum.</li>\n",
    "            <li>Reduce it too slowly and you may still bounce around a lot and, if stopped after too few iterations, \n",
    "                may end up\n",
    "                with a suboptimal solution.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_schedule(t):\n",
    "    return 5 / (t + 50)\n",
    "    \n",
    "def stochastic_gradient_descent_for_ols_linear_regression_with_simulated_annealing(X, y, num_epochs):\n",
    "    \n",
    "    m, n = X.shape\n",
    "    beta = np.random.randn(n) \n",
    "    Jvals = np.zeros(num_epochs * m)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(m):\n",
    "            rand_idx = np.random.randint(m)\n",
    "            xi = X[rand_idx:rand_idx + 1]\n",
    "            yi = y[rand_idx:rand_idx + 1]\n",
    "            alpha = learning_schedule(epoch * m + i)\n",
    "            beta -= alpha * xi.T.dot(xi.dot(beta) - yi)\n",
    "            Jvals[epoch * m + i] = J(X, y, beta)\n",
    " \n",
    "    return beta, Jvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([350.85798617, 175.92858728,  -2.2216496 ,  -1.22026818])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Stochastic Gradient Descent\n",
    "beta, Jvals = stochastic_gradient_descent_for_ols_linear_regression_with_simulated_annealing(X, y, num_epochs = 50)\n",
    "\n",
    "# Display beta\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.title(\"$J$ during learning\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.xlim(1, Jvals.size)\n",
    "plt.ylabel(\"$J$\")\n",
    "plt.ylim(3500, 50000)\n",
    "xvals = np.linspace(1, Jvals.size, Jvals.size)\n",
    "plt.scatter(xvals, Jvals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Mini-Batch Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>Batch Gradient Descent computes gradients from the full training set.</li>\n",
    "    <li>Stochastic Gradient Descent computes gradients from just one example.</li>\n",
    "    <li>Mini-Batch Gradient Descent lies between the two:\n",
    "        <ul>\n",
    "            <li>It computes gradients from a small randomly-selected subset of the training set, called a\n",
    "                <b>mini-batch</b>.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Since it lies between the two:\n",
    "        <ul>\n",
    "            <li>It may bounce less and get closer to the global minimum than SGD&hellip;\n",
    "                <ul>\n",
    "                    <li>&hellip;although both of them can reach the global minimum with a good learning schedule.</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Its time and memory costs lie between the two.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The Normal Equation versus Gradient Descent</h1>\n",
    "<ul>\n",
    "    <li>Efficiency/scaling-up to large training sets:\n",
    "        <ul>\n",
    "            <li>Normal Equation: \n",
    "                <ul>\n",
    "                    <li>is linear in $m$, so can handle large training sets efficiently if they fit into\n",
    "                        main memory;\n",
    "                    </li>\n",
    "                    <li>but it has to compute the inverse (or psueudo-inverse) of a $n \\times n$ matrix, which takes\n",
    "                        time between quadratic and cubic in $n$, and so is only feasible for smallish $n$ (up to\n",
    "                        a few thousand).\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Gradient Descent:\n",
    "                <ul>\n",
    "                    <li>SGD scales really well to huge $m$;</li>\n",
    "                    <li>All three Gradient Descent methods can handle huge $n$ (even 100s of 1000s).</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Finding the global minimum for OLS regression:\n",
    "        <ul>\n",
    "            <li>Normal Equation: guaranteed to find the global minimum.</li>\n",
    "            <li>Gradient Descent: all a bit dependent on number of iterations, learning rate, learning schedule.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Feature scaling:\n",
    "        <ul>\n",
    "            <li>Normal Equation: scaling is not needed. \n",
    "            </li>\n",
    "            <li>Gradient Descent: scaling <em>is</em> needed.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Finally, Gradient Descent is a general method, whereas the Normal Equation is only for OLS regression.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Non-Convex Functions</h1>\n",
    "<ul>\n",
    "    <li>The loss function for OLS regression is convex and it has a slope that never changes abruptly.\n",
    "        <ul>\n",
    "            <li>This gives us good 'guarantees' about reaching the minimum\n",
    "                (depending on such things as running for long enough, using a learning rate that isn't too high,\n",
    "                and whether we are using Batch, Mini-Batch or Stochastic Gradient Descent).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>But Gradient Descent is a generic method: you can use it to find the minima of other loss functions.</li>\n",
    "    <li>But not all loss functions are convex, which can cause problems for Gradient Descent:\n",
    "        <figure>\n",
    "            <img src=\"images/local_minima.png\" />\n",
    "        </figure>\n",
    "        <ul>\n",
    "            <li>The algorithm might converge to a local minimum, instead of the global minimum.</li>\n",
    "            <li>It may take a long time to cross a plateau.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>What do we do about this?\n",
    "        <ul>\n",
    "            <li>One thing is to prefer Stochastic Gradient Descent (or Mini-Batch Gradient Descent):\n",
    "                because of the way they 'bounce around', they might even escape a\n",
    "                local minimum, and might even get to the global minimum.\n",
    "            </li>\n",
    "            <li>In this context, simulated annealing is also useful: updates start out 'large' allowing these\n",
    "                algorithms to make \n",
    "                progress and even escape local minima; but, over time, updates get smaller, allowing \n",
    "                these algorithms to settle at or near the global minimum.\n",
    "            </li>\n",
    "            <li>But, if using simulated annealing, if you reduce the learning rate too quickly, you may \n",
    "                stil get stuck in a local minimum.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
