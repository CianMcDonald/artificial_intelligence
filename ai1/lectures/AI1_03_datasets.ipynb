{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Datasets</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.random import rand\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Features</h1>\n",
    "<ul>\n",
    "    <li>Suppose we want to store data about objects, such as houses.</li>\n",
    "    <li><b>Features</b> describe the houses, e.g.\n",
    "        <ul>\n",
    "            <li>$\\mathit{flarea}$: the total floor area (in square metres);</li>\n",
    "            <li>$\\mathit{bdrms}$: the number of bedrooms;</li>\n",
    "            <li> $\\mathit{bthrms}$: the number of bathrooms.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>A particular house has <b>values</b> for the features:\n",
    "        <ul>\n",
    "            <li>e.g. your house: $\\mathit{flarea} = 126, \\mathit{bdrms} = 3, \\mathit{bthrms} = 1$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Then we can represent a house using a vector:\n",
    "        <ul>\n",
    "            <li>e.g. your house: $\\cv{126\\\\3\\\\1}$\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>We will always use $n$ to refer to the number of features, e.g. above $n = 3$.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Examples</h1> \n",
    "<ul>\n",
    "    <li>Suppose we collect a <b>dataset</b> containing data about lots of houses, e.g.:\n",
    "        $$\\cv{126\\\\3\\\\1} \\,\\, \\cv{92.9\\\\3\\\\2} \\,\\,\\cv{171.9\\\\4\\\\3} \\,\\, \\cv{79\\\\3\\\\1}$$\n",
    "    </li>\n",
    "    <li>Each member of this dataset is called an <b>example</b>, and we will use $m$ to refer to the number of examples, e.g.\n",
    "        above $m = 4$.\n",
    "    </li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Dataset notation</h1>\n",
    "<ul>\n",
    "    <li>We will use a <em>superscript</em> to index the examples.\n",
    "        <ul>\n",
    "            <li>\n",
    "                $\\v{x}^{(i)}$ will be the $i$th example.\n",
    "            </li>\n",
    "            <li>\n",
    "                The first example in the dataset is $\\v{x}^{(1)}$, the second is $\\v{x}^{(2)}$, $\\ldots$, \n",
    "                the last is $\\v{x}^{(m)}$ (Note, we index from 1.)\n",
    "            </li>\n",
    "            <li>\n",
    "                We're writing the superscript in parentheses to make it clear that we are using it for indexing.\n",
    "                It is not 'raising to a power'. If we want to raise to a power, we will drop the parentheses.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>We will use a <em>subscript</em> to index the features (again starting from 1).</li>\n",
    "    <li>Class exercise. Using the dataset from above:\n",
    "        <ul>\n",
    "            <li>what is $\\v{x}_2^{(1)}$?</li>\n",
    "            <li>what is $\\v{x}_1^{(2)}$?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Dataset as a matrix</h1>\n",
    "<ul>\n",
    "    <li>We can represent a dataset $\\Set{\\v{x}^{(1)}, \\v{x}^{(2)}, \\ldots, \\v{x}^{(m)}}$ as a $m \\times n$\n",
    "        matrix $\\v{X}$ as follows:\n",
    "        $$\\v{X} = \\begin{bmatrix}\n",
    "              \\v{x}_1^{(1)} & \\v{x}_2^{(1)} & \\ldots & \\v{x}_n^{(1)} \\\\\n",
    "              \\v{x}_1^{(2)} & \\v{x}_2^{(2)} & \\ldots & \\v{x}_n^{(2)} \\\\\n",
    "              \\vdots        & \\vdots        & \\vdots & \\vdots \\\\\n",
    "              \\v{x}_1^{(m)} & \\v{x}_2^{(m)} & \\ldots & \\v{x}_n^{(m)} \\\\\n",
    "              \\end{bmatrix}\n",
    "        $$\n",
    "    </li>\n",
    "    <li>Note how each example becomes a <em>row</em> in $\\v{X}$.</li>\n",
    "    <li>You can think of row $i$ as the transpose of $\\v{x}^{(i)}$.</li>\n",
    "    <li>For the example dataset, we get:\n",
    "        $$\\v{X} = \n",
    "            \\begin{bmatrix}\n",
    "                126 & 3 & 1 \\\\\n",
    "                92.9 & 3 & 2 \\\\\n",
    "                171.9 & 4 & 3 \\\\\n",
    "                79 & 3 & 1\n",
    "            \\end{bmatrix}\n",
    "        $$\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Cork Property Prices Dataset</h1>\n",
    "<ul>\n",
    "    <li>In August 2019, I scraped a dataset of property prices for Cork city from www.daft.ie.</li>\n",
    "    <li>They are in a CSV file. Each line in the file is an example, representing one house.</li>\n",
    "    <li>Hence, each line of the file contains the feature-values for the floor area, number of bedrooms, number of\n",
    "        bathrooms, and several other features that we will ignore for now.\n",
    "    </li>\n",
    "    <li>We will use the pandas library:\n",
    "        <ul>\n",
    "            <li>to read the dataset from the csv file into what pandas calls a DataFrame;</li>\n",
    "            <li>to explore the dataset: looking at values and computing summary statistics.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Then we will extract some of the features (columns) and convert to a numpy 2D array, before using the data\n",
    "        to find houses similar to yours.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Using pandas to Read and Explore the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['flarea', 'bdrms', 'bthrms', 'price'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The features\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flarea    float64\n",
       "bdrms       int64\n",
       "bthrms      int64\n",
       "price       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flarea</th>\n",
       "      <th>bdrms</th>\n",
       "      <th>bthrms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>464.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>125.460151</td>\n",
       "      <td>3.329741</td>\n",
       "      <td>2.120690</td>\n",
       "      <td>352.297414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.692202</td>\n",
       "      <td>1.068445</td>\n",
       "      <td>1.061033</td>\n",
       "      <td>197.464495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>575.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1495.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           flarea       bdrms      bthrms        price\n",
       "count  464.000000  464.000000  464.000000   464.000000\n",
       "mean   125.460151    3.329741    2.120690   352.297414\n",
       "std     70.692202    1.068445    1.061033   197.464495\n",
       "min     40.000000    1.000000    1.000000    95.000000\n",
       "25%     82.000000    3.000000    1.000000   235.000000\n",
       "50%    110.000000    3.000000    2.000000   295.000000\n",
       "75%    140.600000    4.000000    3.000000   395.000000\n",
       "max    575.000000    9.000000    6.000000  1495.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flarea</th>\n",
       "      <th>bdrms</th>\n",
       "      <th>bthrms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111.9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120.8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flarea  bdrms  bthrms  price\n",
       "0   111.9      3       3    305\n",
       "1    95.0      3       3    255\n",
       "2   120.8      3       3    275"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A few of the examples\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Convert to a numpy 2D array</h2>\n",
    "<ul>\n",
    "    <li>We will select certain features (columns) from the pandas DataFrame\n",
    "        and convert to a 2D numpy array\n",
    "    </li>\n",
    "    <li>(Later in the module, we will use a <code>ColumnTransformer</code> to do this.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features we want to select\n",
    "features = [\"flarea\", \"bdrms\", \"bthrms\"]\n",
    "\n",
    "# Extract these features and convert to numy 2D array\n",
    "X = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111.9,   3. ,   3. ],\n",
       "       [ 95. ,   3. ,   3. ],\n",
       "       [120.8,   3. ,   3. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at a few rows in X - to show you that we now have a 2D numpy array\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Similarity &amp; Distance</h1>\n",
    "<ul>\n",
    "    <li>In AI, we often want to know how <em>similar</em> one object is to another.\n",
    "        <ul>\n",
    "            <li>E.g. how similar is my house to yours?</li>\n",
    "            <li>E.g. which house in our dataset is most similar to yours?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>In fact, here we are instead going to measure how <em>different</em> they are using a <b>distance function</b>.\n",
    "        <ul>\n",
    "            <li>(N.B. This is not about geographical distance.)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Let $\\v{x}$ be one vector of feature values and $\\v{x}'$ be another.</li>\n",
    "    <li>Simplest is to measure their <b>Euclidean distance</b>:\n",
    "        $$d(\\v{x}, \\v{x}') = \\sqrt{(\\v{x}_1 - \\v{x}_1')^2 + (\\v{x}_2 - \\v{x}_2')^2 + \\ldots + (\\v{x}_n - \\v{x}_n')^2}$$\n",
    "        or, more concisely:\n",
    "        $$d(\\v{x}, \\v{x}') = \\sqrt{\\sum_{j=1}^n(\\v{x}_j - \\v{x}_j')^2}$$\n",
    "    </li>\n",
    "    <li>Euclidean distance has a minimum value of 0 (meaning identical) but no maximum value (depends on your data).</li>\n",
    "    <li>Class exercise. What is the Euclidean distance between $\\v{x} = \\cv{100\\\\1\\\\4}$ and $\\v{x}' = \\cv{100\\\\5\\\\1}$?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Euclidean Distance in numpy</h2>\n",
    "<ul>\n",
    "    <li>It has a nice vectorized implementation (no loop!) using numpy:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc(x, xprime):\n",
    "    return np.sqrt(np.sum((x - xprime)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.026297590440446"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "your_house = np.array([126.0, 3, 1])\n",
    "my_house = np.array([107.0, 2, 1])\n",
    "\n",
    "euc(your_house, my_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>We can compute the distance between your house and all the houses in X.</li>\n",
    "    <li>(We have to write a loop here, because our <code>euc</code> function is not vectorized.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [euc(your_house, x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.241137595009741, 31.064449134018133, 5.571355310873651]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to show you, here are the first 3 distances\n",
    "dists[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0332473082471605"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even better, we can, with one line of code, find the most similar house\n",
    "np.min([euc(your_house, x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even better again, we can find which house is the most similar\n",
    "np.argmin([euc(your_house, x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flarea    125.74\n",
       "bdrms       3.00\n",
       "bthrms      2.00\n",
       "price     398.00\n",
       "Name: 196, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best of all, we can display the most similar house\n",
    "df.iloc[np.argmin([euc(your_house, x) for x in X])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Problems with Euclidean distance</h1>\n",
    "<ul>\n",
    "    <li>There are at least two problems with Euclidean distance (and many other distance measures too):\n",
    "        <ul>\n",
    "            <li>Features with different scales;</li>\n",
    "            <li>Features that are correlated with each other;</li>\n",
    "            <li>The curse of dimensionality.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Scaling Numeric Values</h1>\n",
    "<ul>\n",
    "    <li>Different numeric-valued features often have very different ranges.\n",
    "        <ul>\n",
    "            <li>E.g. the values for floor area are going to range from a few tens to a few hundreds of square metres.</li>\n",
    "            <li>But the number of bedrooms and bathrooms is going to range from 0 to a dozen or so at most.\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        When computing the Euclidean distance, features with large ranges will dominate the distance calculations, \n",
    "        thus giving features with small ranges negligible influence.\n",
    "    </li>\n",
    "    <li>\n",
    "        E.g., consider your house $\\v{x} = \\cv{126\\\\3\\\\1}$ and two others, $\\v{y} = \\cv{131\\\\3\\\\1}$ and\n",
    "        $\\v{z} = \\cv{126\\\\7\\\\1}$. \n",
    "        <ul>\n",
    "            <li><em>Intuitively</em>, which house is more similar to yours, $\\v{y}$ or $\\v{z}$?</li>\n",
    "            <li>Now compute the Euclidean distances.</li>\n",
    "            <li>According to these distances, which house is more similar to yours?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        The solution is to <b>scale</b> (or 'normalize') the values so that they have similar ranges.\n",
    "    </li>\n",
    "    <li>There are several ways to do this. One is <b>min-max scaling</b>, bu the one we'll discuss is <b>standardization</b>.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Standardization</h2>\n",
    "<ul>\n",
    "    <!--\n",
    "    <li>In some cases, you don't want feature values to have the same range but to have the same mean\n",
    "        and even the same variance\n",
    "    </li>\n",
    "    -->\n",
    "    <li>\n",
    "        One idea is <b>mean centering</b>, where you subtract the mean value of the feature.\n",
    "        <ul>\n",
    "            <li>If you do this to all values, some of the new values will be positive and some will be negative and \n",
    "                their mean will be approximately zero.\n",
    "                </li>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>But better still is <b>standardization</b>, in which you subtract the mean and divide by the standard\n",
    "        deviation:\n",
    "        $$\\v{x}_j \\gets \\frac{\\v{x}_j - \\mu_j}{\\sigma_j}$$\n",
    "        where $\\mu_j$ is the mean of the values for feature $j$ and $\\sigma_j$ is their standard deviation\n",
    "    </li>\n",
    "    <li>\n",
    "        If you use this, then the mean will be approximately zero, the standard deviation will be 1.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Standardization in scikit-learn</h2>\n",
    "<ul>\n",
    "    <li>scikit-learn provides a class called <code>StandardScaler</code>.\n",
    "    </li>\n",
    "    <li>It uses means and standard deviations that it calculates from your dataset. (Statisticians would say that it should\n",
    "        use the population mean and standard deviation, but these are generally not known.)\n",
    "    </li>\n",
    "    <li>We create the scaler and then run its <code>fit</code> and <code>transform</code> methods.</li>\n",
    "    <li>(Later in the module, when we are using a <code>ColumnTransformer</code>, running these methods\n",
    "        will be done for us.)\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19202665, -0.30895098,  0.82962481],\n",
       "       [-0.43134924, -0.30895098,  0.82962481],\n",
       "       [-0.06599286, -0.30895098,  0.82962481]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at a few rows in X\n",
    "X_scaled[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00764486, -0.30895098, -1.05736495])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scale your house too\n",
    "# Don't try to understand or copy this code - it's a hack that you won't need\n",
    "your_house = np.array([[126.0, 3, 1]])\n",
    "your_house_scaled = scaler.transform(your_house)[0]\n",
    "your_house_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see what effect this has had, let's see which house is most similar to yours\n",
    "np.argmin([euc(your_house_scaled, x) for x in X_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flarea    122.4\n",
       "bdrms       3.0\n",
       "bthrms      1.0\n",
       "price     295.0\n",
       "Name: 328, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[np.argmin([euc(your_house_scaled, x) for x in X_scaled])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Features that are Correlated</h1>\n",
    "<ul>\n",
    "    <li>Let's start with an extreme example. \n",
    "        <ul>\n",
    "            <li>Suppose one feature is the floor area in square metres and\n",
    "                another is the floor area in square feet.\n",
    "                Then it's clear that, even after scaling, when calculating distances, floor area will have greater\n",
    "                influence than other features, such as the number of bedrooms, because it is in the dataset twice.\n",
    "            </li>\n",
    "            <li>Examples are often less stark. For example, floor area and the number of bedrooms are correlated,\n",
    "                and so their contributions to the distance calculations are not independent of each other.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Ideally the features should be independent (at least, linearly independent).</li>\n",
    "    <li>Yet, few people who use distances do anything about this problem!</li>\n",
    "    <li>Solution (which we're not covering in detail) include feature weighting and projections to\n",
    "        a hew feature space whose features are (linearly) independent (e.g. using Principal Component\n",
    "        Analysis).\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The Curse of Dimensionality</h1>\n",
    "<ul>\n",
    "    <li>In some datasets, examples have thousands or even millions of features.\n",
    "        <ul>\n",
    "            <li>E.g. datasets from astronomy;</li>\n",
    "            <li>E.g. datasets of images and videos;</li>\n",
    "            <li>E.g. datasets of documents where each unique word is a feature.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Is it better or worse to have more features?\n",
    "        <ul>\n",
    "            <li>Storage and processing costs increase.</li>\n",
    "            <li>Apart from efficiency, intuitively, more features is better:\n",
    "                <ul>\n",
    "                    <li>e.g. describing houses more completely.</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>But, counter-intuitively, that isn't true in general.\n",
    "                <ul>\n",
    "                    <li>As the number of features grows, algorithms that use distance and density, will find it harder \n",
    "                        to find good solutions.\n",
    "                    </li>\n",
    "                    <li>The problems that arise as the number of features grows have been called <b>the curse of dimensionality</b>.\n",
    "    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Example of the Curse of Dimensionality</h2>\n",
    "<ul>\n",
    "    <li>The code that follows (which you don't need to study):\n",
    "        <ul>\n",
    "            <li>generates a random dataset where $m = 400$ and $n = 2$ and both features have values in $[0, 1)$;\n",
    "            </li>\n",
    "            <li>computes the Euclidean distance between all pairs of examples;</li>\n",
    "            <li>finds $d_{\\mathit{min}}$, the smallest of these distances;</li>\n",
    "            <li>finds $d_{\\mathit{max}}$, the largest of the distances;</li>\n",
    "            <li>computes the ratio $\\frac{d_{\\mathit{max}}}{d_{\\mathit{min}}}$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>It then does this all again but with $n = 3, 4, 5,\\ldots,500$.</li>\n",
    "    <li>Then it plots the ratios that it has computed ($y$-axis, but note its scale) against $n$ ($x$-axis).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = 400\n",
    "n_range = range(1, 500)\n",
    "\n",
    "ratios = []\n",
    "for n in n_range:\n",
    "    X = rand(m, n)\n",
    "    dists = euclidean_distances(X)\n",
    "    non_zero_dists = dists[dists > 0]\n",
    "    ratios += [np.max(non_zero_dists) / (np.min(non_zero_dists))]\n",
    "    \n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title(\"Ratio of max distance to min distance in datasets with ever more features\")\n",
    "plt.scatter(n_range, ratios)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"n\")\n",
    "plt.xlim(0, 500)\n",
    "plt.ylabel(\"ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>As $n \\rightarrow \\infty$, $d_{\\mathit{max}} \\rightarrow d_{\\mathit{min}}$, so their rato tends to 1.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2520569303045033,\n",
       " 1.2841162240034278,\n",
       " 1.2756593774651939,\n",
       " 1.247233364402702,\n",
       " 1.241606577686801]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since it may not be clear from the graph, we'll show the last 5 of the ratios that it calculated\n",
    "ratios[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>We conclude (counter-intutively) that examples become equi-distant!</li>\n",
    "    <li>This obviously undermines methods that depend on finding objects that are similar to each other, as we were\n",
    "        doing earlier &mdash; with more features, the most similar object becomes more arbitrary!\n",
    "    </li>\n",
    "    <li>The problem extends to other distance/similarity measures, e.g. cosine similarity.</li>\n",
    "    <li>Fortunately, there are lots of methods available for reducing dimensionality.\n",
    "        One solution is to retain the principle components found by Principal Component Analysis. This is\n",
    "        interesting because PCA was suggested above as a solution to the problem of correlated features. \n",
    "        It can actually help us solve both problems.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
