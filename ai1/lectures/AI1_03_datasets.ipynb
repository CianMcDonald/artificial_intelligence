{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Datasets</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.random import rand\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Features</h1>\n",
    "<ul>\n",
    "    <li>Suppose we want to store data about objects, such as houses.</li>\n",
    "    <li><b>Features</b> describe the houses, e.g.\n",
    "        <ul>\n",
    "            <li>$\\mathit{flarea}$: the total floor area (in square metres);</li>\n",
    "            <li>$\\mathit{bdrms}$: the number of bedrooms;</li>\n",
    "            <li> $\\mathit{bthrms}$: the number of bathrooms.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>A particular house has <b>values</b> for the features:\n",
    "        <ul>\n",
    "            <li>e.g. your house: $\\mathit{flarea} = 126, \\mathit{bdrms} = 3, \\mathit{bthrms} = 1$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Then we can represent a house using a vector:\n",
    "        <ul>\n",
    "            <li>e.g. your house: $\\cv{126\\\\3\\\\1}$\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>We will always use $n$ to refer to the number of features, e.g. above $n = 3$.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Examples</h1> \n",
    "<ul>\n",
    "    <li>Suppose we collect a <b>dataset</b> containing data about lots of houses, e.g.:\n",
    "        $$\\cv{126\\\\3\\\\1} \\,\\, \\cv{92.9\\\\3\\\\2} \\,\\,\\cv{171.9\\\\4\\\\3} \\,\\, \\cv{79\\\\3\\\\1}$$\n",
    "    </li>\n",
    "    <li>Each member of this dataset is called an <b>example</b>, and we will use $m$ to refer to the number of examples, e.g.\n",
    "        above $m = 4$.\n",
    "    </li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Dataset notation</h1>\n",
    "<ul>\n",
    "    <li>We will use a <em>superscript</em> to index the examples.\n",
    "        <ul>\n",
    "            <li>\n",
    "                $\\v{x}^{(i)}$ will be the $i$th example.\n",
    "            </li>\n",
    "            <li>\n",
    "                The first example in the dataset is $\\v{x}^{(1)}$, the second is $\\v{x}^{(2)}$, $\\ldots$, \n",
    "                the last is $\\v{x}^{(m)}$ (Note, we index from 1.)\n",
    "            </li>\n",
    "            <li>\n",
    "                We're writing the superscript in parentheses to make it clear that we are using it for indexing.\n",
    "                It is not 'raising to a power'. If we want to raise to a power, we will drop the parentheses.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>We will use a <em>subscript</em> to index the features (again starting from 1).</li>\n",
    "    <li>Class exercise. Using the dataset from above:\n",
    "        <ul>\n",
    "            <li>what is $\\v{x}_2^{(1)}$?</li>\n",
    "            <li>what is $\\v{x}_1^{(2)}$?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Dataset as a matrix</h1>\n",
    "<ul>\n",
    "    <li>We can represent a dataset $\\Set{\\v{x}^{(1)}, \\v{x}^{(2)}, \\ldots, \\v{x}^{(m)}}$ as a $m \\times n$\n",
    "        matrix $\\v{X}$ as follows:\n",
    "        $$\\v{X} = \\begin{bmatrix}\n",
    "              \\v{x}_1^{(1)} & \\v{x}_2^{(1)} & \\ldots & \\v{x}_n^{(1)} \\\\\n",
    "              \\v{x}_1^{(2)} & \\v{x}_2^{(2)} & \\ldots & \\v{x}_n^{(2)} \\\\\n",
    "              \\vdots        & \\vdots        & \\vdots & \\vdots \\\\\n",
    "              \\v{x}_1^{(m)} & \\v{x}_2^{(m)} & \\ldots & \\v{x}_n^{(m)} \\\\\n",
    "              \\end{bmatrix}\n",
    "        $$\n",
    "    </li>\n",
    "    <li>Note how each example becomes a <em>row</em> in $\\v{X}$.</li>\n",
    "    <li>You can think of row $i$ as the transpose of $\\v{x}^{(i)}$.</li>\n",
    "    <li>For the example dataset, we get:\n",
    "        $$\\v{X} = \n",
    "            \\begin{bmatrix}\n",
    "                126 & 3 & 1 \\\\\n",
    "                92.9 & 3 & 2 \\\\\n",
    "                171.9 & 4 & 3 \\\\\n",
    "                79 & 3 & 1\n",
    "            \\end{bmatrix}\n",
    "        $$\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Cork Property Prices Dataset</h1>\n",
    "<ul>\n",
    "    <li>In August 2019, I scraped a dataset of property prices for Cork city from www.daft.ie.</li>\n",
    "    <li>They are in a CSV file. Each line in the file is an example, representing one house.</li>\n",
    "    <li>Hence, each line of the file contains the feature-values for the floor area, number of bedrooms, number of\n",
    "        bathrooms, and several other features that we will ignore for now.\n",
    "    </li>\n",
    "    <li>We will use the pandas library:\n",
    "        <ul>\n",
    "            <li>to read the dataset from the csv file into what pandas calls a DataFrame;</li>\n",
    "            <li>to explore the dataset: looking at values and computing summary statistics.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Then we will extract some of the features (columns) and convert to a numpy 2D array, before using the data\n",
    "        to find houses similar to yours.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Using pandas to Read and Explore the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dimensions\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['flarea', 'bdrms', 'bthrms', 'price'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The features\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flarea    float64\n",
       "bdrms       int64\n",
       "bthrms      int64\n",
       "price       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 464 entries, 0 to 463\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   flarea  464 non-null    float64\n",
      " 1   bdrms   464 non-null    int64  \n",
      " 2   bthrms  464 non-null    int64  \n",
      " 3   price   464 non-null    int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 14.6 KB\n"
     ]
    }
   ],
   "source": [
    "# The columns and datatypes (again) but also whether there are any nulls in the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flarea</th>\n",
       "      <th>bdrms</th>\n",
       "      <th>bthrms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>464.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>125.460151</td>\n",
       "      <td>3.329741</td>\n",
       "      <td>2.120690</td>\n",
       "      <td>352.297414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.692202</td>\n",
       "      <td>1.068445</td>\n",
       "      <td>1.061033</td>\n",
       "      <td>197.464495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>575.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1495.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           flarea       bdrms      bthrms        price\n",
       "count  464.000000  464.000000  464.000000   464.000000\n",
       "mean   125.460151    3.329741    2.120690   352.297414\n",
       "std     70.692202    1.068445    1.061033   197.464495\n",
       "min     40.000000    1.000000    1.000000    95.000000\n",
       "25%     82.000000    3.000000    1.000000   235.000000\n",
       "50%    110.000000    3.000000    2.000000   295.000000\n",
       "75%    140.600000    4.000000    3.000000   395.000000\n",
       "max    575.000000    9.000000    6.000000  1495.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flarea</th>\n",
       "      <th>bdrms</th>\n",
       "      <th>bthrms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111.9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120.8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flarea  bdrms  bthrms  price\n",
       "0   111.9      3       3    305\n",
       "1    95.0      3       3    255\n",
       "2   120.8      3       3    275"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A few of the examples\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Convert to a numpy 2D array</h2>\n",
    "<ul>\n",
    "    <li>We will select certain features (columns) from the pandas DataFrame\n",
    "        and convert to a 2D numpy array\n",
    "    </li>\n",
    "    <li>(Later in the module, we will use a <code>ColumnTransformer</code> to do this.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features we want to select\n",
    "features = [\"flarea\", \"bdrms\", \"bthrms\"]\n",
    "\n",
    "# Extract these features and convert to numpy 2D array\n",
    "X = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111.9,   3. ,   3. ],\n",
       "       [ 95. ,   3. ,   3. ],\n",
       "       [120.8,   3. ,   3. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at a few rows in X - to show you that we now have a 2D numpy array\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Similarity &amp; Distance</h1>\n",
    "<ul>\n",
    "    <li>In AI, we often want to know how <em>similar</em> one object is to another.\n",
    "        <ul>\n",
    "            <li>E.g. how similar is my house to yours?</li>\n",
    "            <li>E.g. which house in our dataset is most similar to yours?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>In fact, here we are instead going to measure how <em>different</em> they are using a <b>distance function</b>.\n",
    "        <ul>\n",
    "            <li>(N.B. This is not about geographical distance.)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Let $\\v{x}$ be one vector of feature values and $\\v{x}'$ be another.</li>\n",
    "    <li>Simplest is to measure their <b>Euclidean distance</b>:\n",
    "        $$d(\\v{x}, \\v{x}') = \\sqrt{(\\v{x}_1 - \\v{x}_1')^2 + (\\v{x}_2 - \\v{x}_2')^2 + \\ldots + (\\v{x}_n - \\v{x}_n')^2}$$\n",
    "        or, more concisely:\n",
    "        $$d(\\v{x}, \\v{x}') = \\sqrt{\\sum_{j=1}^n(\\v{x}_j - \\v{x}_j')^2}$$\n",
    "    </li>\n",
    "    <li>Euclidean distance has a minimum value of 0 (meaning identical) but no maximum value (depends on your data).</li>\n",
    "    <li>Class exercise. What is the Euclidean distance between $\\v{x} = \\cv{100\\\\1\\\\4}$ and $\\v{x}' = \\cv{100\\\\5\\\\1}$?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Euclidean Distance in numpy</h2>\n",
    "<ul>\n",
    "    <li>It has a nice vectorized implementation (no loop!) using numpy:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc(x, xprime):\n",
    "    return np.sqrt(np.sum((x - xprime)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.026297590440446"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "your_house = np.array([126.0, 3, 1])\n",
    "my_house = np.array([107.0, 2, 1])\n",
    "\n",
    "euc(your_house, my_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>We can compute the distance between your house and all the houses in X.</li>\n",
    "    <li>(We have to write a loop here, because our <code>euc</code> function is not vectorized.)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [euc(your_house, x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.241137595009741, 31.064449134018133, 5.571355310873651]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to show you, here are the first 3 distances\n",
    "dists[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0332473082471605"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even better, we can, with one line of code, find the most similar house\n",
    "np.min([euc(your_house, x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even better again, we can find which house is the most similar\n",
    "np.argmin([euc(your_house, x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flarea    125.74\n",
       "bdrms       3.00\n",
       "bthrms      2.00\n",
       "price     398.00\n",
       "Name: 196, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best of all, we can display the most similar house\n",
    "df.iloc[np.argmin([euc(your_house, x) for x in X])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Problems with Euclidean distance</h1>\n",
    "<ul>\n",
    "    <li>There are at least three problems with Euclidean distance (and many other distance measures too):\n",
    "        <ul>\n",
    "            <li>Features with different scales;</li>\n",
    "            <li>Features that are correlated with each other;</li>\n",
    "            <li>The curse of dimensionality.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Scaling Numeric Values</h1>\n",
    "<ul>\n",
    "    <li>Different numeric-valued features often have very different ranges.\n",
    "        <ul>\n",
    "            <li>E.g. the values for floor area are going to range from a few tens to a few hundreds of square metres.</li>\n",
    "            <li>But the number of bedrooms and bathrooms is going to range from 0 to a dozen or so at most.\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        When computing the Euclidean distance, features with large ranges will dominate the distance calculations, \n",
    "        thus giving features with small ranges negligible influence.\n",
    "    </li>\n",
    "    <li>\n",
    "        E.g., consider your house $\\v{x} = \\cv{126\\\\3\\\\1}$ and two others, $\\v{y} = \\cv{131\\\\3\\\\1}$ and\n",
    "        $\\v{z} = \\cv{126\\\\7\\\\1}$. \n",
    "        <ul>\n",
    "            <li><em>Intuitively</em>, which house is more similar to yours, $\\v{y}$ or $\\v{z}$?</li>\n",
    "            <li>Now compute the Euclidean distances.</li>\n",
    "            <li>According to these distances, which house is more similar to yours?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        The solution is to <b>scale</b> (or 'normalize') the values so that they have similar ranges.\n",
    "    </li>\n",
    "    <li>There are several ways to do this. One is <b>min-max scaling</b>, but the one we'll discuss is <b>standardization</b>.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Standardization</h2>\n",
    "<ul>\n",
    "    <!--\n",
    "    <li>In some cases, you don't want feature values to have the same range but to have the same mean\n",
    "        and even the same variance\n",
    "    </li>\n",
    "    -->\n",
    "    <li>\n",
    "        One idea is <b>mean centering</b>, where you subtract the mean value of the feature.\n",
    "        <ul>\n",
    "            <li>If you do this to all values, some of the new values will be positive and some will be negative and \n",
    "                their mean will be approximately zero.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>But better still is <b>standardization</b>, in which you subtract the mean and divide by the standard\n",
    "        deviation:\n",
    "        $$\\v{x}_j \\gets \\frac{\\v{x}_j - \\mu_j}{\\sigma_j}$$\n",
    "        where $\\mu_j$ is the mean of the values for feature $j$ and $\\sigma_j$ is their standard deviation\n",
    "    </li>\n",
    "    <li>\n",
    "        If you use this, then the mean will be approximately zero, the standard deviation will be 1.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Standardization in scikit-learn</h2>\n",
    "<ul>\n",
    "    <li>scikit-learn provides a class called <code>StandardScaler</code>.\n",
    "    </li>\n",
    "    <li>It uses means and standard deviations that it calculates from your dataset. (Statisticians would say that it should\n",
    "        use the population mean and standard deviation, but these are generally not known.)\n",
    "    </li>\n",
    "    <li>We create the scaler and then run its <code>fit</code> and <code>transform</code> methods.</li>\n",
    "    <li>(Later in the module, when we are using a <code>ColumnTransformer</code>, running these methods\n",
    "        will be done for us.)\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19202665, -0.30895098,  0.82962481],\n",
       "       [-0.43134924, -0.30895098,  0.82962481],\n",
       "       [-0.06599286, -0.30895098,  0.82962481]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at a few rows in X\n",
    "X_scaled[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00764486, -0.30895098, -1.05736495])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's scale your house too\n",
    "# Don't try to understand or copy this code - it's a hack that you won't need\n",
    "your_house = np.array([[126.0, 3, 1]])\n",
    "your_house_scaled = scaler.transform(your_house)[0]\n",
    "your_house_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see what effect this has had, let's see which house is most similar to yours\n",
    "np.argmin([euc(your_house_scaled, x) for x in X_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flarea    122.4\n",
       "bdrms       3.0\n",
       "bthrms      1.0\n",
       "price     295.0\n",
       "Name: 328, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[np.argmin([euc(your_house_scaled, x) for x in X_scaled])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Features that are Correlated</h1>\n",
    "<ul>\n",
    "    <li>Let's start with an extreme example. \n",
    "        <ul>\n",
    "            <li>Suppose one feature is the floor area in square metres and\n",
    "                another is the floor area in square feet.\n",
    "                Then it's clear that, even after scaling, when calculating distances, floor area will have greater\n",
    "                influence than other features, such as the number of bedrooms, because it is in the dataset twice.\n",
    "            </li>\n",
    "            <li>Examples are often less stark. For example, floor area and the number of bedrooms are correlated,\n",
    "                and so their contributions to the distance calculations are not independent of each other.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Ideally the features should be independent (at least, linearly independent).</li>\n",
    "    <li>Yet, few people who use distances do anything about this problem!</li>\n",
    "    <li>Solutions (which we're not covering in detail) include feature weighting and projections to\n",
    "        a new feature space whose features are (linearly) independent (e.g. using Principal Component\n",
    "        Analysis).\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The Curse of Dimensionality</h1>\n",
    "<ul>\n",
    "    <li>In some datasets, examples have thousands or even millions of features.\n",
    "        <ul>\n",
    "            <li>E.g. datasets from astronomy;</li>\n",
    "            <li>E.g. datasets of images and videos;</li>\n",
    "            <li>E.g. datasets of documents where each unique word is a feature.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Is it better or worse to have more features?\n",
    "        <ul>\n",
    "            <li>Storage and processing costs increase.</li>\n",
    "            <li>Apart from efficiency, intuitively, more features is better:\n",
    "                <ul>\n",
    "                    <li>e.g. describing houses more completely.</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>But, counter-intuitively, that isn't true in general.\n",
    "                <ul>\n",
    "                    <li>As the number of features grows, algorithms that use distance and density, will find it harder \n",
    "                        to find good solutions.\n",
    "                    </li>\n",
    "                    <li>The problems that arise as the number of features grows have been called <b>the curse of dimensionality</b>.\n",
    "    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Example of the Curse of Dimensionality</h2>\n",
    "<ul>\n",
    "    <li>The code that follows (which you don't need to study):\n",
    "        <ul>\n",
    "            <li>generates a random dataset where $m = 400$ and $n = 2$ and both features have values in $[0, 1)$;\n",
    "            </li>\n",
    "            <li>computes the Euclidean distance between all pairs of examples;</li>\n",
    "            <li>finds $d_{\\mathit{min}}$, the smallest of these distances;</li>\n",
    "            <li>finds $d_{\\mathit{max}}$, the largest of the distances;</li>\n",
    "            <li>computes the ratio $\\frac{d_{\\mathit{max}}}{d_{\\mathit{min}}}$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>It then does this all again but with $n = 3, 4, 5,\\ldots,500$.</li>\n",
    "    <li>Then it plots the ratios that it has computed ($y$-axis, but note its scale) against $n$ ($x$-axis).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = 400\n",
    "n_range = range(1, 500)\n",
    "\n",
    "ratios = []\n",
    "for n in n_range:\n",
    "    X = rand(m, n)\n",
    "    dists = euclidean_distances(X)\n",
    "    non_zero_dists = dists[dists > 0]\n",
    "    ratios += [np.max(non_zero_dists) / (np.min(non_zero_dists))]\n",
    "    \n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.title(\"Ratio of max distance to min distance in datasets with ever more features\")\n",
    "plt.scatter(n_range, ratios)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"n\")\n",
    "plt.xlim(0, 500)\n",
    "plt.ylabel(\"ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>As $n \\rightarrow \\infty$, $d_{\\mathit{max}} \\rightarrow d_{\\mathit{min}}$, so their ratio tends to 1.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2591308099625442,\n",
       " 1.2590473591652522,\n",
       " 1.2520789067802196,\n",
       " 1.2458021668678823,\n",
       " 1.2617260697884]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since it may not be clear from the graph, we'll show the last 5 of the ratios that it calculated\n",
    "ratios[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>We conclude (counter-intutively) that examples become equi-distant!</li>\n",
    "    <li>This obviously undermines methods that depend on finding objects that are similar to each other, as we were\n",
    "        doing earlier &mdash; with more features, the most similar object becomes more arbitrary!\n",
    "    </li>\n",
    "    <li>The problem extends to other distance/similarity measures, e.g. cosine similarity.</li>\n",
    "    <li>Fortunately, there are lots of methods available for reducing dimensionality.\n",
    "        One solution is to retain the principle components found by Principal Component Analysis. This is\n",
    "        interesting because PCA was suggested above as a solution to the problem of correlated features. \n",
    "        It can actually help us solve both problems.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
