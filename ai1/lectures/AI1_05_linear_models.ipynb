{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>CS4618: Artificial Intelligence I</h1>\n",
    "<h1>Linear Models</h1>\n",
    "<h2>\n",
    "    Derek Bridge<br>\n",
    "    School of Computer Science and Information Technology<br>\n",
    "    University College Cork\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1>Initialization</h1>\n",
    "$\\newcommand{\\Set}[1]{\\{#1\\}}$ \n",
    "$\\newcommand{\\Tuple}[1]{\\langle#1\\rangle}$ \n",
    "$\\newcommand{\\v}[1]{\\pmb{#1}}$ \n",
    "$\\newcommand{\\cv}[1]{\\begin{bmatrix}#1\\end{bmatrix}}$ \n",
    "$\\newcommand{\\rv}[1]{[#1]}$ \n",
    "$\\DeclareMathOperator{\\argmax}{arg\\,max}$ \n",
    "$\\DeclareMathOperator{\\argmin}{arg\\,min}$ \n",
    "$\\DeclareMathOperator{\\dist}{dist}$\n",
    "$\\DeclareMathOperator{\\abs}{abs}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Equations</h1>\n",
    "<ul>\n",
    "    <li>From school, the equation of a straight line:\n",
    "        $$y = a + bx$$\n",
    "        E.g. $y = 3 + 2x$\n",
    "    </li>\n",
    "    <li>From the point of view of plotting this line, what's $a$? What's $b$?</li>\n",
    "    <li>In general,\n",
    "        $$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$$\n",
    "        <ul>\n",
    "            <li>$\\beta_0,\\ldots,\\beta_n$ are numbers, called the <b>coefficients</b>;</li>\n",
    "            <li>$x_1,\\ldots,x_n$ are the variables;</li>\n",
    "            <li>each of the things being added together is called a <b>term</b>.</li>\n",
    "        </ul>\n",
    "        So a linear equation is the sum of a number of terms, where each term is either a constant or the\n",
    "        product of a constant and a variable.\n",
    "    </li>\n",
    "    <li>Given a linear equation and the values of the variables ($x_1,\\ldots,x_n$), we can <b>evaluate</b>\n",
    "        the equation, i.e. work out the value of $y$.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Class exercises</h1>\n",
    "<ul>\n",
    "    <li>Which of these are linear equations?\n",
    "        <ol>\n",
    "            <li>$y = 6 + 2x_1 + 4x_3 + x_7$</li>\n",
    "            <li>$y = 6x_1 - 3x_2$</li>\n",
    "            <li>$y = 3 + \\sin(x_1)$</li>\n",
    "            <li>$y = 3x_0^0 + 7x_1^1 + 19x_3^2$</li>\n",
    "            <li>$y = 3 + 14x_1x_2 + 12x_3$</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Evaluate $y = 2 + 3x_1 + 4x_2 + 5x_3$:\n",
    "        <ol>\n",
    "            <li>in the case that $x_1 = 1, x_2 = 1, x_3 = 1$</li>\n",
    "            <li>in the case that $x_1 = 0, x_2 = 1, x_3 = 5$</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Equations and Vectors</h1>\n",
    "<ul>\n",
    "    <li>Give a linear equation $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$, \n",
    "        <ul>\n",
    "            <li>we can gather the variables into a row vector $\\rv{x_1,x_2, \\ldots, x_n}$</li>\n",
    "            <li>we can gather the coefficients (except $\\beta_0$) into a column vector\n",
    "                $\\cv{\\beta_1\\\\ \\beta_2\\\\ \\vdots\\\\ \\beta_n}$ (of the same dimension, $n$)\n",
    "            </li>\n",
    "            <li>E.g. from $y = 12 + 3x_1 + 4x_2 + 5x_3$, we get $\\v{x} = \\rv{x_1, x_2, x_3}$ and\n",
    "                $\\v{\\beta} = \\cv{3\\\\4\\\\5}$\n",
    "            </li>\n",
    "            <li>What are the two vectors for $y = 7 + 20x_1 + x_3$?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Hence, the linear equation $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$ can\n",
    "        equivalently be written in this form:\n",
    "        $$y = \\beta_0 + \\sum_{i=1}^n \\v{\\beta}_i\\v{x}_i$$\n",
    "    </li>\n",
    "    <li>It can also, equivalently, be written in this form:\n",
    "        $$y = \\beta_0 + \\v{x}\\v{\\beta}$$\n",
    "    </li>\n",
    "    <li>Hence, to evaluate a linear equation, simply multiply the two vectors and add $\\beta_0$.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Evaluating a linear equation in numpy</h2>\n",
    "<ul>\n",
    "    <li>If you had to evaluate a linear equation, you might be tempted to write a loop:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate y = 12 + 3x1 + 4x2 + 5x3 in the case where x1=7, x2=3, x3=20\n",
    "y = 12\n",
    "for (beta_i, x_i) in zip(np.array([3, 4, 5]), np.array([7, 3, 20])):\n",
    "    y += beta_i * x_i\n",
    "    \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>\n",
    "        But you don't need to write your own loop: use numpy library's matrix multiplication method:\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 12 + np.array([3, 4, 5]).dot(np.array([7, 3, 20]))\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Linear Equations and Vectors: Tidying the maths</h2>\n",
    "<ul>\n",
    "    <li>Give a linear equation $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$, \n",
    "        <ul>\n",
    "            <li>we can gather the variables into a row vector but include an extra variable \n",
    "                $x_0$, whose value will always be 1: $\\rv{1,x_1,x_2, \\ldots, x_n}$</li>\n",
    "            <li>we can gather <em>all</em> the coefficients (including $\\beta_0$) into a column vector\n",
    "                $\\cv{\\beta_0\\\\ \\beta_1\\\\ \\beta_2\\\\ \\vdots\\\\ \\beta_n}$ (of the same dimension, $n+1$)\n",
    "            </li>\n",
    "            <li>E.g. from $y = 12 + 3x_1 + 4x_2 + 5x_3$, we get $\\v{x} = \\rv{1, x_1, x_2, x_3}$ and\n",
    "                $\\v{\\beta} = \\cv{12\\\\3\\\\4\\\\5}$\n",
    "            </li>\n",
    "            <li>What are the two vectors for $y = 7 + 20x_1 + x_3$?</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Hence, the linear equation $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n$ can\n",
    "        equivalently be written in this form:\n",
    "        $$y = \\sum_{i=0}^n \\v{\\beta}_i\\v{x}_i$$\n",
    "    </li>\n",
    "    <li>It can also, equivalently, be written in this form:\n",
    "        $$y = \\v{x}\\v{\\beta}$$\n",
    "    </li>\n",
    "    <li>Hence, to evaluate a linear equation, simply multiply the two vectors.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([12, 3, 4, 5]).dot(np.array([1, 7, 3, 20]))\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Evaluating Linear Equations and Matrices</h1>\n",
    "<ul>\n",
    "    <li>Suppose you need to evaluate the same linear equation lots of times &mdash; with different values \n",
    "        for $\\v{x}$\n",
    "        <ul>\n",
    "            <li>E.g. evaluate $y = 12 + 3x_1 + 4x_2 + 5x_3$ for\n",
    "                <ul>\n",
    "                    <li>$x_1 = 7, x_2 = 3, x_3 = 20$ and</li>\n",
    "                    <li>$x_1 = 10, x_2 = 20, x_3 = 0$ and</li>\n",
    "                    <li>$x_1 = 1, x_2 = 1, x_3 = 1$ and</li>\n",
    "                    <li>$x_1 = 100, x_2 = 0, x_3 = -2$</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>If we gather the values for the variables into a matrix, $\\v{X}$, but with an extra element \n",
    "        $\\v{x}_0^{(i)}$ in each row $i$, all of which will be 1, then we can obtain all the\n",
    "        results by simple matrix multiplication:\n",
    "        $$y = \\v{X}\\v{\\beta}$$\n",
    "        <ul>\n",
    "            <li>E.g.\n",
    "                $$\n",
    "                \\v{y} =\n",
    "                \\begin{bmatrix}\n",
    "                    1 & 7 & 3 & 20 \\\\\n",
    "                    1 & 10 & 20 & 0 \\\\\n",
    "                    1 & 1 & 1 & 1 \\\\\n",
    "                    1 & 100 & 0 & -2\n",
    "                \\end{bmatrix}\n",
    "                \\cv{12\\\\ 3\\\\ 4\\\\ 5}\n",
    "                $$\n",
    "            </li>\n",
    "        </ul>\n",
    "        It produces a vector of results, e.g. $\\v{y} = \\cv{145\\\\122\\\\24\\\\302}$\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Evaluating a linear equation multiple times in numpy</h2>\n",
    "<ul>\n",
    "    <li>Same story: no loop, use matrix mutliplication:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([145, 122,  24, 302])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[1, 7, 3, 20], [1, 10, 20, 0], [1, 1, 1, 1], [1, 100, 0, -2]]).dot(np.array([12, 3, 4, 5]))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>This is <b>vectorization</b> again: concise, fast code!</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Models</h1>\n",
    "<ul>\n",
    "    <li>Recall: We want to learn a model from a labeled training set.</li>\n",
    "    <li>For now, let's content ourselves with learning a linear model.</li>\n",
    "    <li>We want  to find a linear equation that best fits the training examples.</li>\n",
    "    <li>We'll start by assuming there's only one feature.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Regression: with one feature</h1>\n",
    "<ul>\n",
    "    <li>We'll read in the Cork Property Prices dataset and ignore all features other than\n",
    "        $\\mathit{flarea}$.\n",
    "    </li>\n",
    "    <li>For the purposes of this explanation, we won't scale the data: so no need for a <code>ColumnTransformer</code>.</li>\n",
    "    <li>We'll also extract the prices (the target values).</li>\n",
    "    <li>Also for the purposes of this explanation, we will use the entire dataset as our training set.\n",
    "        <ul>\n",
    "            <li>We will learn later that using <em>all</em> the data for training is usually not\n",
    "                the right thing to do.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_training_set():\n",
    "    plt.figure()\n",
    "    plt.title(\"Training set\")\n",
    "    plt.scatter(df[\"flarea\"], df[\"price\"], color = 'green')\n",
    "    plt.xlabel(\"Floor area (sq metres)\")\n",
    "    plt.xlim(0, 500)\n",
    "    plt.ylabel(\"Price (000 euros)\")\n",
    "    plt.ylim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "show_training_set()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>The goal of our learning algorithm is to fit a linear model to this data:\n",
    "        $$\\hat{y} = \\beta_0 + \\beta_1 \\times \\mathit{flarea}$$\n",
    "    </li>\n",
    "    <li>In other words, our goal is to choose values for $\\beta_0$ and $\\beta_1$.\n",
    "        <ul>\n",
    "            <li>From the point of view of plotting this line, what's $\\beta_0$? What's $\\beta_1$?</li>\n",
    "            <li>E.g. we could choose $\\beta_0 = 800$ and $\\beta_1 = -5$.</li>\n",
    "            <li>Or we could choose $\\beta_0 = 200$ and $\\beta_1 = 5$.</li>\n",
    "        </ul>\n",
    "        Lets' refer to any particular choice as $h_{\\v{\\beta}}$ ($h$ for <b>hypothesis</b>).\n",
    "            <ul>\n",
    "                <li>The first example above is $h_{\\rv{800, -5}}$</li>\n",
    "                <li>The second example above is $h_{\\rv{200, 5}}$</li>\n",
    "            </ul>\n",
    "    </li>\n",
    "    <li>But there is an infinite set of linear models the algorithm can choose from:\n",
    "        <ul>\n",
    "            <li>an infinite number of straight lines it can draw;</li>\n",
    "            <li>or, equivalently, an infinite set of values from which it can pick $\\beta_0$ and $\\beta_1$.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>We want it to choose the one that best fits the data.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Loss functions</h1>\n",
    "<ul>\n",
    "    <li>The algorithm needs a function that measures how well a model (hypothesis) fits the data.\n",
    "        <ul>\n",
    "            <li>This is called its <b>loss function</b>, designated $J$.</li>\n",
    "            <li>The function takes in a particular $h_{\\v{\\beta}}$ and gives it a score.\n",
    "                <ul>\n",
    "                    <li>Low numbers are better!</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>For each $\\v{x}$ in the training set, it will compare $h_{\\v{\\beta}}(\\v{x})$, which is the\n",
    "                <em>prediction</em> that $h_{\\v{\\beta}}$ makes on $\\v{x}$, with the <em>actual</em>\n",
    "                value $y$.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The loss function most usually used for linear regression is the <b>mean squared error</b>, i.e.:\n",
    "        <ul>\n",
    "            <li>the difference between the prediction and the actual value, squared;</li>\n",
    "            <li>but averaged over all the examples in the training set.</li>\n",
    "        </ul>\n",
    "        $$J(\\v{X}, \\v{y}, \\v{\\beta}) = \\frac{1}{m}\\sum_{i=1}^m(h_{\\v{\\beta}}(\\v{x}^{i)}) - \\v{y}^{(i)})^2$$\n",
    "        <ul>\n",
    "            <li>Why do you think we square the differences? (Two reasons.)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The best model is the one that <em>minimizes</em> the loss function.</li>\n",
    "    <li>This is often referred to as <b>ordinary least-squares regression</b> (OLS):\n",
    "        <ul>\n",
    "            <li>\"least\" because we are minimizing the loss;</li>\n",
    "            <li>\"squares\" because the loss is mean squared error; and</li>\n",
    "            <li>\"ordinary\" to distinguish it from many variants that came later.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>In fact, we often divide by 2:\n",
    "        $$J(\\v{X}, \\v{y}, \\v{\\beta}) = \\frac{1}{2m}\\sum_{i=1}^m(h_{\\v{\\beta}}(\\v{x}^{i)}) - \\v{y}^{(i)})^2$$\n",
    "        &mdash; the 'winner' is still the same, but this makes the calculus 'tidier' later\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>The loss function in numpy</h2>\n",
    "<ul>\n",
    "    <li>Looks like a loop: work out $h_{\\v{\\beta}}$ for each $\\v{x}^{(i)}$.\n",
    "        <ul>\n",
    "            <li>But $h_{\\v{\\beta}}$ is a linear equation, and we want to evaluate it lots of times (for\n",
    "                each example $\\v{x}^{(i)}$).\n",
    "            </li>\n",
    "            <li>So we use the vectorized approach from above (assuming all the examples contain an\n",
    "                extra element, $\\v{x}_0^{(i)} = 1$).\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>So our code can simply do this:\n",
    "        $$J(\\v{X}, \\v{y}, \\v{\\beta}) = \\frac{1}{2m}(\\v{X}\\v{\\beta} - \\v{y})^2$$\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for OLS regression (assumes X contains all 1s in its first column)\n",
    "def J(X, y, beta):\n",
    "    return np.mean((X.dot(beta) - y) ** 2) / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Now let's find a model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature-values (just flarea) and the target values \n",
    "X = df[[\"flarea\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Add the extra column to X\n",
    "X_augmented = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Keep modifying $\\v{\\beta}$ until you find the lowest loss:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e8884622a54d449510dd3ecdf358a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, description='beta0', max=1000), FloatSlider(value=0.0, description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_linear_model(beta0, beta1):\n",
    "    show_training_set()\n",
    "    beta = np.array([beta0, beta1])\n",
    "    xvals = np.array([[1, 0], [1, 500]])\n",
    "    plt.plot(xvals, xvals.dot(beta), color = \"blue\")\n",
    "    plt.show()\n",
    "    print(\"Loss: \" + str(J(X_augmented, y, beta)))\n",
    "    \n",
    "interactive_plot = interactive(show_linear_model, beta0=(0,1000), beta1=(-10,10,.1))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Linear Regression: with multiple features</h1>\n",
    "<ul>\n",
    "    <li>We considered only one feature ($\\mathit{flarea}$).\n",
    "        <ul>\n",
    "            <li>This enabled easy visualisation on a 2D plot.</li>\n",
    "            <li>The model is a straight line.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The only differences when we move to more than one feature:\n",
    "        <ul>\n",
    "            <li>We can't plot so easily.</li>\n",
    "            <li>The model is a plane when there are two features.</li>\n",
    "            <li>The model is a hyperplane when there are more than two features.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><em>All the maths and the Python for the loss function remain the same</em>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Now let's find a model using two features</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to read the CSV file\n",
    "df = pd.read_csv(\"../datasets/dataset_corkA.csv\")\n",
    "\n",
    "# Get the feature-values (just bdrms and bthrms) and the target values \n",
    "X = df[[\"bdrms\", \"bthrms\"]].values\n",
    "y = df[\"price\"].values\n",
    "\n",
    "# Add the extra column to X\n",
    "X_augmented = add_dummy_feature(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_3D_training_set():\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    ax.set_title(\"Training set and learned model\")\n",
    "    ax.scatter(X[:,0], X[:,1], y, color = \"green\")\n",
    "    ax.set_xlabel(\"Bedrooms\")\n",
    "    ax.set_xlim(0,10)\n",
    "    ax.set_ylabel(\"Bathrooms\")\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.set_zlabel(\"Price (000 euros)\")\n",
    "    ax.set_zlim(0, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Keep modifying $\\v{\\beta}$ until you find the lowest loss:</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b773955a28943f5824620cae2c086e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, description='beta0', max=1000), IntSlider(value=0, description='bet…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_linear_model(beta0, beta1, beta2):\n",
    "    show_3D_training_set()\n",
    "    beta = np.array([beta0, beta1, beta2])\n",
    "    xvals = np.linspace(0, 10, 2)\n",
    "    yvals = np.linspace(0, 10, 2)\n",
    "    xxvals, yyvals = np.meshgrid(xvals, yvals)\n",
    "    plt.gca().plot_surface(xxvals, yyvals, beta[0] + beta[1] * xxvals + beta[2] * yyvals, color=(0, 0, 1, 0.2))\n",
    "    plt.show()\n",
    "    print(\"Loss: \" + str(J(X_augmented, y, beta)))\n",
    "    \n",
    "interactive_plot = interactive(show_linear_model, beta0=(0,1000), beta1=(-100,100), beta2=(-100,100))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>We can't do a similar example with 3 or more features&hellip;\n",
    "        <ul>\n",
    "            <li>&hellip;because we can't plot them.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Finding OLS Models</h1>\n",
    "<ul>\n",
    "    <li>We've been trying out different values for $\\v{\\beta}$, looking for the model with\n",
    "        lowest mean squared error&hellip;\n",
    "        <ul>\n",
    "            <li>&hellip;by trial and error!</li>\n",
    "        </ul>\n",
    "        In practice, it is not done by trial-and-error.\n",
    "    </li>\n",
    "    <li>There are two main methods:\n",
    "        <ul>\n",
    "            <li>the <b>normal equation</b> (<code>LinearRegression</code> class in scikit-learn);</li>\n",
    "            <li>various forms of <b>gradient descent</b> (<code>SGDRegressor</code> class in scikit-learn).</li>\n",
    "        </ul>\n",
    "        We'll look at the details in the next two lectures.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
